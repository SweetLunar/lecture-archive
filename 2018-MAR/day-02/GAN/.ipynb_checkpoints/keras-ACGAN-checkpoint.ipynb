{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division                                                 \n",
    "from __future__ import print_function                                           \n",
    "from __future__ import absolute_import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ACGAN():\n",
    "    def __init__(self): \n",
    "        self.configuration()\n",
    "\n",
    "        self.build_generator()\n",
    "        self.build_discriminator()\n",
    "        self.compile_models()\n",
    "        \n",
    "        self.build_adversarial()\n",
    "        self.compile_adversarial()\n",
    "        \n",
    "    def configuration(self):\n",
    "        self.verbose = 0\n",
    "        self.image_width  = 28\n",
    "        self.image_height = 28\n",
    "        self.image_channels = 1\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        self.label_size = 1\n",
    "        self.noise_size = 100\n",
    "        self.image_shape = (self.image_height, self.image_width, self.image_channels)\n",
    "        \n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    def generator_network(self):\n",
    "        net = Sequential()\n",
    "        net.add(Dense(128*7*7, activation=\"relu\", input_dim=self.noise_size))\n",
    "        net.add(Reshape((7, 7, 128)))\n",
    "        net.add(BatchNormalization(momentum=0.8))\n",
    "        net.add(UpSampling2D())\n",
    "        net.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization(momentum=0.8))\n",
    "        net.add(UpSampling2D())\n",
    "        net.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        net.add(Activation(\"relu\"))\n",
    "        net.add(BatchNormalization(momentum=0.8))\n",
    "        net.add(Conv2D(self.image_channels, kernel_size=3, padding='same'))\n",
    "        net.add(Activation(\"tanh\"))\n",
    "        if (self.verbose == 1):\n",
    "            net.summary()\n",
    "        return net\n",
    "    \n",
    "    def generator_input(self):\n",
    "        noise = Input(shape=(self.noise_size,))\n",
    "        label = Input(shape=(self.label_size,), dtype='int32')\n",
    "        return  [noise, label]\n",
    "\n",
    "    def generator_output(self, model, gen_in):\n",
    "        noise, label = gen_in[0], gen_in[1]\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.noise_size)(label))\n",
    "        image_seed = multiply([noise, label_embedding])\n",
    "        image_generated = model(image_seed)\n",
    "        return image_generated\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = self.generator_network()\n",
    "\n",
    "        gen_in = self.generator_input()   \n",
    "        gen_out = self.generator_output(model, gen_in)\n",
    "        self.generator = Model(gen_in, gen_out) \n",
    "        \n",
    "    def discriminator_network(self):\n",
    "        net = Sequential()\n",
    "        net.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.image_shape, padding=\"same\"))\n",
    "        net.add(LeakyReLU(alpha=0.2))\n",
    "        net.add(Dropout(0.25))\n",
    "        net.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        net.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        net.add(LeakyReLU(alpha=0.2))\n",
    "        net.add(Dropout(0.25))\n",
    "        net.add(BatchNormalization(momentum=0.8))\n",
    "        net.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        net.add(LeakyReLU(alpha=0.2))\n",
    "        net.add(Dropout(0.25))\n",
    "        net.add(BatchNormalization(momentum=0.8))\n",
    "        net.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        net.add(LeakyReLU(alpha=0.2))\n",
    "        net.add(Dropout(0.25))\n",
    "        net.add(Flatten())\n",
    "        if (self.verbose == 1):\n",
    "            net.summary()\n",
    "        return net\n",
    "\n",
    "    def discriminator_input(self):\n",
    "        return Input(shape=self.image_shape)\n",
    "\n",
    "    def discriminator_output(self, model, dis_in):\n",
    "        features = model(dis_in)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(features)\n",
    "        label = Dense(self.num_classes+1, activation=\"softmax\")(features)\n",
    "        return [ validity, label ]\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        model = self.discriminator_network();\n",
    "        \n",
    "        if (self.verbose == 1):\n",
    "            model.summary()       \n",
    "\n",
    "        dis_in = self.discriminator_input()\n",
    "        dis_out = self.discriminator_output(model, dis_in)\n",
    "        self.discriminator = Model(dis_in, dis_out)\n",
    "\n",
    "    def compile_models(self):\n",
    "        gen_losses = ['binary_crossentropy']\n",
    "        dis_losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "        self.generator.compile(loss=gen_losses, optimizer=self.optimizer)\n",
    "        self.discriminator.compile(loss=dis_losses, optimizer=self.optimizer, metrics=['accuracy'])\n",
    "        \n",
    "    def adversarial_input(self):\n",
    "        noise = Input(shape=(self.noise_size,))\n",
    "        label = Input(shape=(self.label_size,))\n",
    "        image_gen = self.generator([noise, label])\n",
    "        return [noise, label], image_gen\n",
    "\n",
    "    def adversarial_output(self, image_gen):\n",
    "        validity, identification = self.discriminator(image_gen)\n",
    "        return [ validity, identification ]\n",
    "    \n",
    "    def compile_adversarial(self):\n",
    "        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "        self.adversarial.compile(loss=losses, optimizer=self.optimizer)\n",
    "        \n",
    "    def build_adversarial(self):\n",
    "        ad_in, image_gen = self.adversarial_input()\n",
    "        self.discriminator.trainable = False\n",
    "        ad_out = self.adversarial_output(image_gen)\n",
    "        self.adversarial = Model(ad_in, ad_out)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=1000):\n",
    "            X_train, y_train, _, _ = self.load_data()\n",
    "            half_batch = int(batch_size/2)\n",
    "\n",
    "            cw1 = {0: 1, 1: 1}\n",
    "            cw2 = {i: self.num_classes / half_batch for i in range(self.num_classes)}\n",
    "            cw2[self.num_classes] = 1 / half_batch\n",
    "            class_weights = [cw1, cw2]\n",
    "            \n",
    "            def run_epoch(epoch):\n",
    "                indexes = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "                imgs = X_train[indexes]\n",
    "                img_labels = y_train[indexes]\n",
    "                noise = np.random.normal(0, 1, (half_batch, self.noise_size))\n",
    "                labels_for_gen = np.random.randint(0, 10, half_batch).reshape(-1, 1)\n",
    "                gen_imgs = self.generator.predict([noise, labels_for_gen])\n",
    "\n",
    "                valid = np.ones((half_batch, 1))\n",
    "                fake = np.zeros((half_batch, 1))\n",
    "\n",
    "                fake_labels = 10 * np.ones(half_batch).reshape(-1, 1)   \n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, [valid, img_labels], class_weight=class_weights)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=class_weights)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.noise_size))\n",
    "                valid = np.ones((batch_size, 1))\n",
    "                sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "                g_loss = self.adversarial.train_on_batch([noise, sampled_labels], [valid, sampled_labels], class_weight=class_weights)\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                run_epoch(epoch)\n",
    "            self.save_model()\n",
    "            self.save_imgs(epoch)\n",
    "\n",
    "    def load_data(self):\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        fig.suptitle(\"ACGAN: Generated digits\", fontsize=12)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"./mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def save_model(self):\n",
    "        def save(model, model_name):\n",
    "            model_path = \"./%s.json\" % model_name\n",
    "            weights_path = \"./%s_weights.hdf5\" % model_name\n",
    "            options = {\"file_arch\": model_path, \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, \"mnist_acgan_generator\")\n",
    "        save(self.discriminator, \"mnist_acgan_discriminator\")\n",
    "        save(self.adversarial, \"mnist_acgan_adversarial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = ACGAN()\n",
    "gan.train(epochs=6000, batch_size=32, save_interval=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
